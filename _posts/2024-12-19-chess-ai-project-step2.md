---
title: "[Chess AI] 2. ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„"
date: 2024-12-19 20:00:00 +0900
categories: [Machine Learning, Chess AI]
tags: [machine-learning, neural-network, chess, data-preprocessing, pytorch, project]
pin: false
math: true
mermaid: true
---

# Chess AI í”„ë¡œì íŠ¸ - Phase 2: ë°ì´í„° ì „ì²˜ë¦¬

Phase 1ì—ì„œ í™˜ê²½ ì„¤ì •ê³¼ ë°ì´í„°ì…‹ì„ í™•ë³´í•œ í›„, Phase 2ì—ì„œëŠ” **ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

## ğŸ“‹ Phase 2 ëª©í‘œ

1. **FEN â†’ Tensor ë³€í™˜**: ì²´ìŠ¤ í¬ì§€ì…˜ì„ Neural Network ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
2. **Evaluation ì •ê·œí™”**: Centipawn í‰ê°€ë¥¼ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
3. **Dataset & DataLoader**: PyTorch Dataset í´ë˜ìŠ¤ ë° Train/Val/Test ë¶„í• 

```mermaid
graph LR
    A[FEN String] --> B[FEN to Tensor<br/>Converter]
    B --> C[13x8x8 Tensor<br/>Position]
    D[Centipawn<br/>Evaluation] --> E[Evaluation<br/>Normalizer]
    E --> F[Normalized Score<br/>-1 to 1]
    C --> G[PyTorch Dataset]
    F --> G
    G --> H[DataLoader<br/>Train/Val/Test]

    style C fill:#ccffcc
    style F fill:#ccccff
    style H fill:#ffcccc
```

---

## Step 2.1: FEN to Tensor ë³€í™˜ êµ¬í˜„

### í…ì„œ í‘œí˜„ ì„¤ê³„

**8Ã—8Ã—13 Tensor í˜•ì‹**:
- **12 planes**: ì²´ìŠ¤ ë§ ì¢…ë¥˜ (White P/N/B/R/Q/K, Black p/n/b/r/q/k)
- **1 plane**: ë©”íƒ€ë°ì´í„° (ìºìŠ¬ë§, ì•™íŒŒìƒ, ì°¨ë¡€)

**ë©”íƒ€ë°ì´í„° ì¸ì½”ë”©**:
- Row 0: ì°¨ë¡€ (1.0=White, 0.0=Black)
- Row 1-4: ìºìŠ¬ë§ ê¶Œí•œ (White K/Q, Black K/Q)
- Row 5: ì•™íŒŒìƒ íŒŒì¼ (0-1 ì •ê·œí™”, -1=ì—†ìŒ)
- Row 6-7: í–¥í›„ ì‚¬ìš© ì˜ˆì•½

### êµ¬í˜„: `FENToTensor` í´ë˜ìŠ¤

**íŒŒì¼**: `src/data_processing/fen_to_tensor.py`

```python
class FENToTensor:
    """Convert chess positions from FEN to tensor representation."""

    PIECE_TO_INDEX = {
        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,
        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11
    }

    def fen_to_tensor(self, fen: str) -> torch.Tensor:
        """Convert FEN to 13x8x8 tensor"""
        board = chess.Board(fen)
        tensor = torch.zeros(13, 8, 8, dtype=torch.float32)

        # Fill piece planes (channels 0-11)
        for square in chess.SQUARES:
            piece = board.piece_at(square)
            if piece is not None:
                piece_index = self.PIECE_TO_INDEX[piece.symbol()]
                rank = chess.square_rank(square)
                file = chess.square_file(square)
                row = 7 - rank  # Flip for tensor representation
                col = file
                tensor[piece_index, row, col] = 1.0

        # Fill metadata plane (channel 12)
        metadata = self._encode_metadata(board)
        tensor[12, :, :] = metadata

        return tensor
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼

```
Test 1: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1
Tensor shape: torch.Size([13, 8, 8])
Non-zero elements: 80
[OK] Board position matches

Test 2: rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1
Tensor shape: torch.Size([13, 8, 8])
Non-zero elements: 72
[OK] Board position matches

Batch shape: torch.Size([3, 13, 8, 8])
[OK] Test Complete!
```

**ì£¼ìš” ê¸°ëŠ¥**:
- âœ… FEN â†’ Tensor ë³€í™˜
- âœ… Tensor â†’ FEN ì—­ë³€í™˜ (ë””ë²„ê¹…ìš©)
- âœ… ë°°ì¹˜ ë³€í™˜ ì§€ì›
- âœ… 100% ì •í™•ë„ ê²€ì¦

---

## Step 2.2: Evaluation Score ì •ê·œí™”

### ì •ê·œí™” ì „ëµ

**ë¬¸ì œì **:
- Centipawn ë²”ìœ„: -8,500 ~ +8,499
- NNì€ bounded output í•„ìš” (ì˜ˆ: tanh â†’ [-1, 1])

**í•´ê²°ì±…**: **tanh ë³€í™˜ ì‚¬ìš©**

$$
\text{normalized} = \tanh\left(\frac{\text{centipawns}}{4000}\right)
$$

**Scale Factor ì„ íƒ**:
- **2000**: ë¹ ë¥¸ í¬í™”, ì‘ì€ ì°¨ì´ ë¯¼ê°
- **4000**: ê¶Œì¥, ê· í˜•ì¡íŒ ë¯¼ê°ë„
- **6000**: ëŠë¦° í¬í™”, í° ì°¨ì´ êµ¬ë¶„

### êµ¬í˜„: `EvaluationNormalizer` í´ë˜ìŠ¤

**íŒŒì¼**: `src/data_processing/evaluation_normalizer.py`

```python
class EvaluationNormalizer:
    """Normalize evaluation scores from centipawns to [-1, 1]."""

    def __init__(self, scale_factor: float = 4000.0):
        self.scale_factor = scale_factor

    def normalize(self, evaluation: float) -> float:
        """Normalize single evaluation score"""
        return np.tanh(evaluation / self.scale_factor)

    def denormalize(self, normalized_score: float) -> float:
        """Convert back to centipawns"""
        normalized_score = np.clip(normalized_score, -0.99999, 0.99999)
        return np.arctanh(normalized_score) * self.scale_factor
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼

| Centipawns | Normalized | Reconstructed | Error |
|------------|------------|---------------|-------|
| 0 | 0.000000 | 0.0 | 0.000000 |
| 100 | 0.024995 | 100.0 | 0.000000 |
| -500 | -0.124353 | -500.0 | 0.000000 |
| 1000 | 0.244919 | 1000.0 | 0.000000 |
| -2000 | -0.462117 | -2000.0 | 0.000000 |
| 4000 | 0.761594 | 4000.0 | 0.000000 |
| 8000 | 0.964028 | 8000.0 | 0.000000 |
| -8500 | -0.971873 | -8500.0 | 0.000000 |

**ì£¼ìš” íŠ¹ì§•**:
- âœ… ì™„ë²½í•œ ì—­ë³€í™˜ (ì˜¤ì°¨ < 0.0001)
- âœ… PyTorch Tensor ì§€ì›
- âœ… ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
- âœ… Edge case ì²˜ë¦¬ (Â±8500 centipawns)

---

## Step 2.3: PyTorch Dataset & DataLoader

### Dataset í´ë˜ìŠ¤ êµ¬í˜„

**íŒŒì¼**: `src/data_processing/chess_dataset.py`

```python
class ChessDataset(Dataset):
    """PyTorch Dataset for chess positions with evaluations."""

    def __init__(self, csv_path: str, scale_factor: float = 4000.0):
        self.df = pd.read_csv(csv_path)
        self.fen_converter = FENToTensor()
        self.eval_normalizer = EvaluationNormalizer(scale_factor)

        # Convert evaluations to numeric
        self.df['evaluation_numeric'] = pd.to_numeric(
            self.df['Analysis'], errors='coerce'
        )
        self.df = self.df.dropna(subset=['evaluation_numeric'])

    def __getitem__(self, idx: int) -> tuple:
        row = self.df.iloc[idx]

        # Convert FEN to tensor
        position_tensor = self.fen_converter.fen_to_tensor(row['FEN'])

        # Normalize evaluation
        normalized_eval = self.eval_normalizer.normalize(
            row['evaluation_numeric']
        )
        eval_tensor = torch.tensor(normalized_eval, dtype=torch.float32)

        return position_tensor, eval_tensor
```

### Train/Val/Test Split

**ë¶„í•  ë¹„ìœ¨**:
- **Train**: 70% (235,832 positions)
- **Validation**: 15% (50,535 positions)
- **Test**: 15% (50,536 positions)

**DataLoader ì„¤ì •**:
```python
train_loader, val_loader, test_loader, dataset = create_dataloaders(
    csv_path="data/fen_analysis.csv",
    batch_size=64,
    train_split=0.7,
    val_split=0.15,
    test_split=0.15,
    scale_factor=4000.0
)
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼

```
Dataset split:
  Train: 235,832 (70.0%)
  Validation: 50,535 (15.0%)
  Test: 50,536 (15.0%)

Batch shapes:
  Positions: torch.Size([64, 13, 8, 8])
  Evaluations: torch.Size([64])
  Evaluation range: [-0.972, 0.972]

Memory per sample: 3.25 KB
Estimated dataset memory: 1070.56 MB
Single batch (32): 104.12 KB
```

---

## ğŸ“Š ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

### í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

**íŒŒì¼**: `src/data_processing/test_pipeline.py`

```python
def test_complete_pipeline():
    # 1. FEN to Tensor Conversion
    converter = FENToTensor()
    position = converter.fen_to_tensor(test_fen)

    # 2. Evaluation Normalization
    normalizer = EvaluationNormalizer(scale_factor=4000.0)
    normalized = normalizer.normalize(evaluation)

    # 3. Dataset Loading
    dataset = ChessDataset(csv_path)

    # 4. DataLoader Creation
    train_loader, val_loader, test_loader = create_dataloaders(...)

    # 5. End-to-End Pipeline
    for positions, evaluations in train_loader:
        # Ready for model training!
        pass
```

### ìµœì¢… ê²°ê³¼

```
[1/5] FEN to Tensor Conversion... [OK]
[2/5] Evaluation Normalization... [OK]
[3/5] Dataset Loading... [OK]
[4/5] DataLoader Creation... [OK]
[5/5] End-to-End Pipeline... [OK]

[SUCCESS] All components working correctly!

Key Statistics:
  Total positions: 336,903
  Train samples: 235,832
  Validation samples: 50,535
  Test samples: 50,536
  Batch size: 64
  Position tensor shape: (13, 8, 8)
  Evaluation range: [-1, 1]

Ready for model training!
```

---

## ğŸ¯ Phase 2 ì£¼ìš” ì„±ê³¼

### âœ… ì™„ë£Œëœ ì‘ì—…

1. **FEN to Tensor ë³€í™˜**
   - 8Ã—8Ã—13 í…ì„œ í‘œí˜„ ì„¤ê³„ ë° êµ¬í˜„
   - ì–‘ë°©í–¥ ë³€í™˜ ì§€ì› (FEN â†” Tensor)
   - 100% ì •í™•ë„ ê²€ì¦

2. **Evaluation ì •ê·œí™”**
   - tanh ê¸°ë°˜ ì •ê·œí™” (scale=4000)
   - ì™„ë²½í•œ ì—­ë³€í™˜ (ì˜¤ì°¨ < 0.0001)
   - PyTorch Tensor ì§€ì›

3. **Dataset & DataLoader**
   - PyTorch Dataset í´ë˜ìŠ¤ êµ¬í˜„
   - Train/Val/Test ë¶„í•  (70/15/15)
   - ë°°ì¹˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ì„±

### ğŸ“ˆ ê¸°ìˆ ì  ì„±ê³¼

- âœ… **ë©”ëª¨ë¦¬ íš¨ìœ¨**: ì „ì²´ ë°ì´í„°ì…‹ 1.07 GB
- âœ… **ë°°ì¹˜ ì²˜ë¦¬**: 64 positions/batch
- âœ… **ë°ì´í„° ê²€ì¦**: 336,903 valid positions
- âœ… **ì •ê·œí™” í’ˆì§ˆ**: Perfect reconstruction
- âœ… **íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„±**: End-to-end tested

### ğŸ“‚ ìƒì„±ëœ íŒŒì¼

```
src/data_processing/
â”œâ”€â”€ fen_to_tensor.py           # FEN to Tensor converter
â”œâ”€â”€ evaluation_normalizer.py   # Evaluation normalizer
â”œâ”€â”€ chess_dataset.py            # PyTorch Dataset class
â””â”€â”€ test_pipeline.py            # Integration tests

data/
â”œâ”€â”€ fen_analysis.csv            # Kaggle dataset
â”œâ”€â”€ normalization_analysis.png  # Normalization visualization
â””â”€â”€ sample_position_tensor.png  # Sample tensor visualization
```

---

## ğŸ”œ ë‹¤ìŒ ë‹¨ê³„: Phase 3 - CNN ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ

### Step 3.1: CNN Architecture Design
- **Input**: 13Ã—8Ã—8 tensor (position)
- **Output**: 1 value (normalized evaluation)
- **Architecture**: Convolutional layers + Batch Normalization + Dropout

### Step 3.2: Model Training
- **Loss Function**: MSE (Mean Squared Error)
- **Optimizer**: Adam with learning rate scheduling
- **Training Loop**: Epochs, validation, early stopping

### Step 3.3: Model Evaluation
- **Metrics**: MSE, MAE, RÂ² score
- **Visualization**: Loss curves, prediction scatter plots
- **Comparison**: Train vs. Validation performance

---

## ğŸ’¡ ë°°ìš´ ì 

1. **Tensor Representation**
   - ì²´ìŠ¤ í¬ì§€ì…˜ì„ 13ê°œ ì±„ë„ë¡œ í‘œí˜„
   - ë©”íƒ€ë°ì´í„°ë¥¼ ë³„ë„ planeì— ì¸ì½”ë”©
   - CNN ì…ë ¥ì— ìµœì í™”ëœ í˜•ì‹

2. **Normalization Strategy**
   - tanh ë³€í™˜ì´ centipawn ì •ê·œí™”ì— íš¨ê³¼ì 
   - scale_factor=4000ì´ ê· í˜•ì¡íŒ ë¯¼ê°ë„ ì œê³µ
   - ì™„ë²½í•œ ì—­ë³€í™˜ ê°€ëŠ¥ (ë””ë²„ê¹… ìš©ì´)

3. **PyTorch Dataset Design**
   - `__getitem__`ì—ì„œ on-the-fly ë³€í™˜
   - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ lazy loading
   - DataLoaderë¡œ ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

4. **Data Pipeline Best Practices**
   - ê° ì»´í¬ë„ŒíŠ¸ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
   - í†µí•© í…ŒìŠ¤íŠ¸ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦
   - ì‹œê°í™”ë¡œ ë°ì´í„° í’ˆì§ˆ í™•ì¸

---

**ë‹¤ìŒ í¬ìŠ¤íŠ¸**: Phase 3 - CNN ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ
